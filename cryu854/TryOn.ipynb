{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "StyleGAN_Local_Editing_Demo.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRkHnRKNWBcq"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/HSinger04/VOGUE-Reimplementation/blob/main/cryu854/TryOn.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXcFTFzd_fbM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25869357-f6f3-48f0-988d-3e136a0a63dc"
      },
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/HSinger04/VOGUE-Reimplementation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'VOGUE-Reimplementation'...\n",
            "remote: Enumerating objects: 191, done.\u001b[K\n",
            "remote: Counting objects: 100% (191/191), done.\u001b[K\n",
            "remote: Compressing objects: 100% (190/190), done.\u001b[K\n",
            "remote: Total 494 (delta 121), reused 0 (delta 0), pack-reused 303\u001b[K\n",
            "Receiving objects: 100% (494/494), 84.58 MiB | 31.05 MiB/s, done.\n",
            "Resolving deltas: 100% (287/287), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDibY5O2MgPM",
        "outputId": "7cd4c947-6074-4ae1-be10-ca0a3b8f4c8f"
      },
      "source": [
        "%cd /content/VOGUE-Reimplementation/cryu854/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/VOGUE-Reimplementation/cryu854\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DompTDT1jSlq"
      },
      "source": [
        "## Mount drive for dataset and weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvCRJckWjVco"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z45486OzOzb8"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOJUgWG3O0W3"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import \\\n",
        "BatchNormalization, ELU, Dense\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWt3jUt_RUHZ"
      },
      "source": [
        "## Global setting whether to use tf.function or not"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG7TJXbwRSF1"
      },
      "source": [
        "# Set true for better performance, False for debugging\n",
        "TF_FUNCTION = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWjWZp0dSCzs"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzsaarYYOdq7"
      },
      "source": [
        "# Pro: Save space in google drive\n",
        "# Contra: Needs to load the whole dataset every time\n",
        "# use list_files to get generate dataset from data in different subdirectories easily\n",
        "data = tf.data.Dataset.list_files(\"/content/drive/MyDrive/Lernen/Coxi/IANNwTF/ffhq-dataset/images1024x1024/\" \n",
        "                                  + \"[0-9]\" * 2\n",
        "                                  + \"000/*.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9qCLxeRY1QZ"
      },
      "source": [
        "## Data pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMSOOrY1pmcW"
      },
      "source": [
        "# Data pipeline constants\n",
        "# shuffle_size shouldn't be much higher than 100. Otherwise, Google Colab runs out of memory\n",
        "shuffle_size = 100\n",
        "BATCH_SIZE = 4\n",
        "PREFETCH_SIZE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yjSvkA3Y0Uj"
      },
      "source": [
        "def decode_ffhq(image_path):\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "    return img\n",
        "\n",
        "# Convert paths to image\n",
        "data = data.map(decode_ffhq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0CMxWCfoawP"
      },
      "source": [
        "# TODO: Show some images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjtlysHExUiQ"
      },
      "source": [
        "# Normalize to [-1, 1] to match StyleGAN2's generator's output\n",
        "data = data.map(lambda x: (tf.cast(x, tf.float32) / 127.5) - 1)\n",
        "# Shuffle whole dataset once\n",
        "data = data.shuffle(buffer_size=shuffle_size)\n",
        "data = data.batch(BATCH_SIZE)\n",
        "# Shuffle batch each iteration \n",
        "# TODO: left out for now due to memory issues\n",
        "#data = data.shuffle(buffer_size=shuffle_size, reshuffle_each_iteration=True)\n",
        "data = data.prefetch(PREFETCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL4Z5lVqhSWp"
      },
      "source": [
        "# Loading trained StyleGAN2 Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73bNpBXfkH0v"
      },
      "source": [
        "## Actually load the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eRqIYoPhUta"
      },
      "source": [
        "!git pull\n",
        "import tensorflow as tf\n",
        "from modules.generator import generator\n",
        "\n",
        "resolution = 1024  \n",
        "config = \"f\"\n",
        "num_labels = 0\n",
        "checkpoint_path = \"/content/drive/MyDrive/Lernen/Coxi/IANNwTF/official_1024x1024/\"\n",
        "\n",
        "Gs = generator(resolution, num_labels, config, randomize_noise=False)\n",
        "ckpt = tf.train.Checkpoint(generator_clone=Gs)\n",
        "print(f'Loading network from {checkpoint_path}...')\n",
        "ckpt.restore(tf.train.latest_checkpoint(checkpoint_path)).expect_partial()\n",
        "# Freeze Generator since we don't want to train it\n",
        "Gs.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeAtzWoZpKCq"
      },
      "source": [
        "## Generate and show images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7UGWODGXP6-"
      },
      "source": [
        "# returns image in the correct range of 0 to 225\n",
        "def get_img(x, truncation_psi, training=False):\n",
        "    # TODO: change comment below better\n",
        "    # Generator returns values that should be clipped to -1 and 1\n",
        "    img = Gs(x, truncation_psi=truncation_psi, training=training)\n",
        "    img = tf.clip_by_value(img, clip_value_min=-1.0, clip_value_max=1.0)\n",
        "    return img\n",
        "\n",
        "if TF_FUNCTION:\n",
        "    get_img = tf.function(get_img)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "545XC_2Hb79c"
      },
      "source": [
        "truncation_psi = 0.5\n",
        "latent_size = 512\n",
        "latents = tf.random.normal([BATCH_SIZE, latent_size])\n",
        "# TODO: from _get_labels\n",
        "labels_indice = [0]*BATCH_SIZE\n",
        "labels = tf.zeros([BATCH_SIZE, 0], tf.float32)\n",
        "# Generate images\n",
        "images = get_img([latents, labels], truncation_psi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aG6cYaidfwa"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# TODO: proper image displaying\n",
        "for i in range(BATCH_SIZE):\n",
        "    temp = images[i]\n",
        "    temp = (temp + 1) * 127.5\n",
        "    plt.imshow(temp.numpy().astype(np.uint8))\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3orRlp3ncedu"
      },
      "source": [
        "## Define code2code model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXI7t96McjiL"
      },
      "source": [
        "# TODO: Maybe leave out. 'w' itself might already be disentangled enough\n",
        "# latent_size = 512\n",
        "\n",
        "# class Code2Code(Model):\n",
        "#     def __init__(hidden_dim, initializer=tf.keras.initializers.GlorotUniform):\n",
        "#         self.layers = [Dense(hidden_dim), BatchNormalization(), ELU(),\n",
        "#                        Dense(512), BatchNormalization(), ELU()]          \n",
        "    \n",
        "    \n",
        "#   @tf.function \n",
        "#   def call(self, x, training=True):\n",
        "#     for layer in self.layers:\n",
        "#       x = layer(x, training = training)\n",
        "\n",
        "#     return x\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0MolKJJADXh"
      },
      "source": [
        "## Training preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSfZF7lmCYSl"
      },
      "source": [
        "## Load VGG and freeze it "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z23-qjcUCZwp"
      },
      "source": [
        "# TODO: remove unnecessary layers. Also, summarize this in external code instead of \n",
        "# creating this cell in both notebooks\n",
        "perc_base_net = tf.keras.applications.EfficientNetB0()\n",
        "# Freeze perc_base_net since we don't want to train it\n",
        "perc_base_net.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wN5U2EkDQuf8"
      },
      "source": [
        "layer_names = (\"block1a_project_conv\", \"block2b_project_conv\", \"block3b_project_conv\", \n",
        "               \"block4c_project_conv\", \"block5c_project_conv\", \"block6d_project_conv\",\n",
        "               \"block7a_project_conv\"\n",
        "               )\n",
        "\n",
        "# layer_indices = []\n",
        "used_layers = []\n",
        "\n",
        "# for i, layer in enumerate(vgg.layers):\n",
        "#     used_layers.append(layer)\n",
        "#     if layer.name in layer_names:\n",
        "#         layer_indices.append(i)\n",
        "#         if len(layer_indices) == len(layer_names):\n",
        "#             break\n",
        "\n",
        "used_layers = [perc_base_net.get_layer(layer_name).output for layer_name in layer_names]\n",
        "\n",
        "perc_net = tf.keras.Model(inputs=perc_base_net.inputs, outputs=used_layers)\n",
        "\n",
        "# Hopefully save memory this way         \n",
        "del perc_base_net\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "NUM_LAYERS = len(layer_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLVyUcZpqva_"
      },
      "source": [
        "## Define perceptual loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNE5p-lWXg9R"
      },
      "source": [
        "def perc_loss(real, fake, loss_tracker):\n",
        "    # TODO: Better description. Also maybe more detail? Point to equation\n",
        "    \"\"\"Returns perceptual loss according to VGG16 activations. See \n",
        "    \"\"\"\n",
        "    \n",
        "    real = tf.image.resize(real, [224, 224])\n",
        "    real = tf.keras.applications.resnet_v2.preprocess_input(real)\n",
        "\n",
        "    fake = tf.image.resize(fake, [224, 224])\n",
        "    fake = tf.keras.applications.resnet_v2.preprocess_input(fake)\n",
        "    \n",
        "    for i, layer in enumerate(vgg.layers):\n",
        "            real = layer(real)\n",
        "            fake = layer(fake)\n",
        "            # TODO: say which corresponds to what\n",
        "            if i == 2 or i == 5 or i == 9 or i == 13 or i == 17:\n",
        "                # normalize in channel dimension\n",
        "                layer_loss = tf.math.l2_normalize(real, axis=-1)\n",
        "                layer_loss -= tf.math.l2_normalize(fake, axis=-1)\n",
        "\n",
        "                # TODO: should be alright, since shape is right, but not fully confirmed\n",
        "                layer_loss = tf.norm(layer_loss, axis=-1)\n",
        "                layer_loss = tf.square(layer_loss)\n",
        "                layer_loss = tf.reduce_mean(layer_loss)\n",
        "\n",
        "                loss_tracker.update_state(layer_loss)\n",
        "\n",
        "if TF_FUNCTION:\n",
        "    perc_loss = tf.function(perc_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d4KU3x_7w_q"
      },
      "source": [
        "def encoder_train_step(model, train_data, optimizer, global_loss_tracker, local_loss_tracker, train_writer):\n",
        "\n",
        "    for inputs in train_data:\n",
        "        \n",
        "        # reset local loss\n",
        "        local_loss_tracker.reset_states()    \n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "\n",
        "            # perc\n",
        "            fakes = model(inputs)\n",
        "            fakes = get_img([fakes, labels], truncation_psi)\n",
        "            perc_loss(inputs, fakes, local_loss_tracker)\n",
        "            loss = local_loss_tracker.result()\n",
        "            # average over the batch manually\n",
        "            # TODO: remove\n",
        "            #loss = tf.math.reduce_mean(loss)\n",
        "            # TODO: remove\n",
        "            print(model.__class_)\n",
        "            gradients = tape.gradient(loss, model.trainable_variables)\n",
        "\n",
        "        # update weights  \n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "        # record global loss\n",
        "        global_loss_tracker.update_state(loss)\n",
        "\n",
        "if TF_FUNCTION:\n",
        "    encoder_train_step = tf.function(encoder_train_step)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJ9aiDH2FXgn"
      },
      "source": [
        "## Instantiate loss trackers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOXQHhouFYwZ"
      },
      "source": [
        "GLOBAL_LOSS_TRACKER = tf.keras.metrics.Mean()\n",
        "LOCAL_LOSS_TRACKER = tf.keras.metrics.Sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfGc4yyVrxTR"
      },
      "source": [
        "## Instantiate train writer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJxfBVm-sBfv"
      },
      "source": [
        "import datetime\n",
        "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "# Set log directory\n",
        "LOG_DIR = \"/content/drive/MyDrive/Lernen/Coxi/IANNwTF/logs/encoder/\" + current_time \n",
        "\n",
        "TRAIN_WRITER = tf.summary.create_file_writer(LOG_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4_YNwsztr60"
      },
      "source": [
        "## Instantiate optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwgANYckttKN"
      },
      "source": [
        "LEARNING_RATE = 0.001\n",
        "OPTIMIZER = tf.keras.optimizers.Adam(LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MD7Kzd7w7GxE"
      },
      "source": [
        "## Instantiate encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L27-rIjG7IaU"
      },
      "source": [
        "# TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZYJlXEtzcCB"
      },
      "source": [
        "#for datum in data:\n",
        "#    print(datum.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1maxy-jHBrX9"
      },
      "source": [
        "# TODO: remove\n",
        "#for datum in data:\n",
        "#    ENCODER(datum)\n",
        "#    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzKqh3lti4rr"
      },
      "source": [
        "## Instantiate q vectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQqIpnpii8Sk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maKNom-trtdp"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgcxEd16refn",
        "outputId": "cd9a7dd5-da3e-4cc0-c928-c82ab934ccb4"
      },
      "source": [
        "NUM_EPOCHS = 10000\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    print(\"Start epoch: \" + str(epoch))\n",
        "\n",
        "    # reset statistics\n",
        "    GLOBAL_LOSS_TRACKER.reset_states()\n",
        "\n",
        "    encoder_train_step(ENCODER, data, OPTIMIZER, GLOBAL_LOSS_TRACKER, LOCAL_LOSS_TRACKER, TRAIN_WRITER)    \n",
        "    data = data.shuffle(buffer_size = shuffle_size)\n",
        "\n",
        "    # write average epoch loss\n",
        "    with TRAIN_WRITER.as_default():\n",
        "        tf.summary.scalar('loss', GLOBAL_LOSS_TRACKER.result(), step=epoch)    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start epoch: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aEbyvDAE9IE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}